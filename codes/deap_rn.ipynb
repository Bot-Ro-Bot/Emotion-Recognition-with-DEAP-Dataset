{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Late Fusion with Weighted Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programmed By: Rabin Nepal\n",
    "\n",
    "Supervisor Name: Dr. Bonny Banerjee\n",
    "\n",
    "University of Memphis\n",
    "\n",
    "Date: Dec, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References \n",
    "\n",
    "* Fusion Algorithm: https://github.com/cerlymarco/MEDIUM_NoteBook/blob/master/NeuralNet_Ensemble/NeuralNet_Ensemble.ipynb\n",
    "* Dataset: https://www.eecs.qmul.ac.uk/mmv/datasets/deap/doc/tac_special_issue_2011.pdf\n",
    "* SOTA: https://paperswithcode.com/sota/eeg-emotion-recognition-on-deap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use the code?\n",
    "\n",
    "change directory to codes and make a virtual environment for python3.8\n",
    "* conda create -n deap_venv python=3.8\n",
    "\n",
    "activate the new virtial environment\n",
    "* conda activate deap_venv\n",
    "\n",
    "install the required python packages \n",
    "* pip3 install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, Layer, LeakyReLU\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.initializers import glorot_uniform,glorot_normal,he_normal,he_uniform\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Set Keras backend seed (TensorFlow backend) for uniform training output\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# global definitions\n",
    "MAIN_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_DIR = os.path.join(MAIN_DIR, \"preprocessed_datasets/DEAP\")\n",
    "FEATURE_SET = [\"feat_set1\",\"feat_set2\",\"feat_set3\"]\n",
    "\n",
    "DATA_DIR =  os.path.join(DATA_DIR,FEATURE_SET[0])\n",
    "\n",
    "SUBJECTS = 32 # 40 samples per subject\n",
    "TEST_SUBJECT = 1 \n",
    "\n",
    "# VALANCE Labels: 1-5 is unpleasant and 5-9 is pleasant\n",
    "V_LABELS = [\"Unpleasant\",\"Pleasant\"]\n",
    "\n",
    "# Arousal Labels: 1-5 is Calm and 5-9 is Excited\n",
    "A_LABELS = [\"Calm\",\"Excited\"]\n",
    "\n",
    "NUM_MODALITIES = 7\n",
    "MODALITIES = [\"EEG\", \"EOG\", \"EMG\", \"GSR\", \"RESP\", \"plet\", \"temp\"]\n",
    "MOD_KEYS = ['mod1', 'mod2', 'mod3', 'mod4', 'mod5', 'mod6', 'mod7']\n",
    "\n",
    "# create a dictionary where each modality is mapped to its respective index, starting from 1\n",
    "MODALITY_INDICES = {modality: index + 1 for index, modality in enumerate(MODALITIES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files from the dataset directory\n",
    "files = glob.glob(DATA_DIR+\"/*.mat\")\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_info = loadmat(files[-1])[list(loadmat(files[-1]).keys())[-1]]\n",
    "sub_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = loadmat(files[3])\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(files):\n",
    "    \"\"\"\n",
    "    Extracts data from the provided list of files.\n",
    "\n",
    "    Parameters:\n",
    "    - files (list): A list containing file paths to extract data from.\n",
    "\n",
    "    Returns:\n",
    "    - data (dict): A dictionary containing data extracted from the files categorized by MOD_KEYS.\n",
    "    - labels_a (list): List of 'lab_a' files' content.\n",
    "    - labels_v (list): List of 'lab_v' files' content.\n",
    "\n",
    "    The function iterates through the provided list of files to extract data based on the provided MOD_KEYS.\n",
    "    Additionally, it separates 'lab_a' and 'lab_v' files' content into separate lists: labels_a and labels_v.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = {key: [] for key in MOD_KEYS}\n",
    "    \n",
    "    # Define a regex pattern to extract the modality number\n",
    "    pattern = r'DEAP_mod(\\d+)_data.mat'\n",
    "\n",
    "    labels_a = []\n",
    "    labels_v = []\n",
    "    \n",
    "    def read_file(file):\n",
    "        d = loadmat(file)\n",
    "        d_key = list(d.keys())[-1]\n",
    "        return d[d_key]\n",
    "    \n",
    "    for file in tqdm.tqdm(files,desc=\"Extracting Data ...\"):\n",
    "        if((\"lab\" in file) or (\"sub\" in file)):\n",
    "            if(\"lab_a\" in file):\n",
    "                labels_a.append(read_file(file))                \n",
    "            \n",
    "            if(\"lab_v\" in file):\n",
    "                labels_v.append(read_file(file))                \n",
    "            continue\n",
    "        \n",
    "        # Extract modality number from file names using regex\n",
    "        key = int(re.search(pattern, file).group(1)) - 1\n",
    "        # print(key)\n",
    "        data[MOD_KEYS[key]] = read_file(file)\n",
    "    \n",
    "    return data,labels_a[0],labels_v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data , labels_a , labels_v = extract_data(files=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count,mod in enumerate(MODALITIES):\n",
    "    print(f\"Shape of Modality-{count+1} ({MODALITIES[count]}) :{data[MOD_KEYS[count]].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_v.shape)\n",
    "print(labels_a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(labels_a[:5])\n",
    "print(labels_v[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition for Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    \"\"\"\n",
    "    A class to compute and visualize performance metrics for the trained model.\n",
    "\n",
    "    Attributes:\n",
    "    - model: The trained machine learning model.\n",
    "    - history: Training history of the model.\n",
    "    - X_test: Test data used for evaluation.\n",
    "    - y_test: True labels of the test data.\n",
    "\n",
    "    Methods:\n",
    "    - plot_loss_accuracy(): Plot training and validation accuracy & loss over epochs.\n",
    "    - plot_confusion_matrix(): Plot the confusion matrix.\n",
    "    - calculate_precision_recall(): Calculate precision-recall curve values.\n",
    "    - calculate_precision_recall_f1(): Calculate precision, recall, and F1-score.\n",
    "    - calculate_auc(): Calculate the Area Under the ROC Curve (AUC).\n",
    "    - plot_roc_curve(): Plot the Receiver Operating Characteristic (ROC) curve.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, history, X_test, y_test):\n",
    "        self.model = model\n",
    "        self.history = history\n",
    "        self.X_test = X_test\n",
    "        self.y_test = np.array([np.argmax(y) for y in y_test])\n",
    "        self.y_pred = np.argmax(model.predict(X_test),axis=1) \n",
    "        \n",
    "        self.labels = [0,1]\n",
    "\n",
    "    def plot_loss_accuracy(self):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        # Plot training & validation accuracy values\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.history.history['accuracy'])\n",
    "        plt.plot(self.history.history['val_accuracy'])\n",
    "        plt.title('Model accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "        # Plot training & validation loss values\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.history.history['loss'])\n",
    "        plt.plot(self.history.history['val_loss'])\n",
    "        plt.title('Model loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_confusion_matrix(self):\n",
    "        cm = confusion_matrix(self.y_test, self.y_pred, labels=self.labels)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.colorbar()\n",
    "\n",
    "        thresh = cm.max() / 2.\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                plt.text(j,i, format(cm[i,j],\"d\"),ha=\"center\", va=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "                \n",
    "        tick_marks = np.arange(len(self.labels))\n",
    "        plt.xticks(tick_marks, self.labels)\n",
    "        plt.yticks(tick_marks, self.labels)\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def calculate_precision_recall(self):\n",
    "        precision, recall, _ = precision_recall_curve(self.y_test, self.y_pred)\n",
    "        return precision, recall\n",
    "    \n",
    "\n",
    "    def calculate_precision_recall_f1(self):\n",
    "        return classification_report(y_true=self.y_test,y_pred=self.y_pred)\n",
    "\n",
    "    def calculate_auc(self):\n",
    "        fpr, tpr, _ = roc_curve(self.y_test, self.y_pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        return fpr, tpr, roc_auc\n",
    "\n",
    "    def plot_roc_curve(self):\n",
    "        fpr, tpr, roc_auc = self.calculate_auc()\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(fpr, tpr, lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Modality Class to Handle Multi-Modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modality:\n",
    "    \"\"\"\n",
    "    A class for handling modality data, including building, training, and evaluating a neural network model.\n",
    "\n",
    "    Args:\n",
    "    - data (numpy.ndarray): Input data for the each modality.\n",
    "    - labels (numpy.ndarray): Corresponding labels for the input data.\n",
    "    - regularization (float): Regularization rate for dropout layers, if applied.\n",
    "\n",
    "    Methods:\n",
    "    - flatten(data): Method to flatten the input data.\n",
    "    - train_test_split(test_size=40, random_state=42): Splits the data into training and test sets.\n",
    "    - build_model(neurons): Builds a neural network model with specified number of neurons.\n",
    "    - train_model(model_name, epochs=1000): Trains the built model for a specified number of epochs.\n",
    "    - plots(): Generates and displays plots for model evaluation metrics.\n",
    "    - get_history(): Retrieves the training history of the model.\n",
    "    - get_model(model_name): Retrieves a trained model given the model's name.\n",
    "    - build_layers(model_name): Builds layers for a trained model to analyze weights and biases.\n",
    "\n",
    "    Attributes:\n",
    "    - labels (numpy.ndarray): Labels corresponding to the data.\n",
    "    - data (numpy.ndarray): Input data for the modality.\n",
    "    - regularization (float): Regularization rate for dropout layers, if applied.\n",
    "    - X_train (numpy.ndarray): Training data after splitting.\n",
    "    - X_test (numpy.ndarray): Test data after splitting.\n",
    "    - y_train (numpy.ndarray): Training labels after splitting.\n",
    "    - y_test (numpy.ndarray): Test labels after splitting.\n",
    "    - model (tf.keras.Model): Neural network model.\n",
    "    - trained_model (tf.keras.Model): Trained neural network model.\n",
    "    - history (tf.keras.callbacks.History): Training history of the model.\n",
    "    - hidden_nodes (int): Number of neurons in the hidden layer.\n",
    "\n",
    "    Usage:\n",
    "    Initialize the class with data and labels, then proceed to build, train, and evaluate the model.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, labels,regularization=None):\n",
    "        self.labels = labels\n",
    "        self.data = data\n",
    "        self.regularization = regularization\n",
    "        \n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.model = None\n",
    "        self.trained_model = None\n",
    "        self.history = None\n",
    "        self.hidden_nodes = None\n",
    "        \n",
    "        self.data = self.flatten(self.data)\n",
    "        self.train_test_split()\n",
    "\n",
    "    @staticmethod\n",
    "    def flatten(data):\n",
    "        print(\"Shape of Original Data:\", data.shape)\n",
    "        data = data.reshape(len(data), -1)\n",
    "        print(\"Shape of Reshaped Data:\", data.shape)\n",
    "        return data\n",
    "\n",
    "    def train_test_split(self, test_size=40, random_state=42):\n",
    "        # Split data into train and test sets\n",
    "        X_train = self.data[:-test_size]\n",
    "        X_test = self.data[-test_size:]\n",
    "        y_train = self.labels[:-test_size]\n",
    "        y_test = self.labels[-test_size:]\n",
    "\n",
    "        # Shuffle indices\n",
    "        num_samples = len(X_train)\n",
    "        shuffled_indices = np.random.RandomState(seed=random_state).permutation(num_samples)\n",
    "\n",
    "        # Use shuffled indices to shuffle both features and labels\n",
    "        self.X_train = X_train[shuffled_indices]\n",
    "        self.y_train = y_train[shuffled_indices]\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "        print(\"X_train shape:\", self.X_train.shape)\n",
    "        print(\"X_test shape:\", self.X_test.shape)\n",
    "        print(\"y_train shape:\", self.y_train.shape)\n",
    "        print(\"y_test shape:\", self.y_test.shape)\n",
    "\n",
    "\n",
    "    def build_model(self,neurons):\n",
    "        self.hidden_nodes=neurons\n",
    "        Inputs = Input(shape=(int(self.data[0].shape[0],),))\n",
    "        x = Dense(units=neurons, activation=\"linear\", kernel_initializer=he_normal(seed=42))(Inputs)\n",
    "        x = LeakyReLU(alpha=0.4)(x)\n",
    "        if(self.regularization is not None):\n",
    "            x = Dropout(self.regularization)(x)\n",
    "        Outputs = Dense(units=2, activation=\"softmax\", kernel_initializer=he_normal(seed=42))(x)\n",
    "\n",
    "        self.model = Model(Inputs, Outputs)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "        self.model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        self.model.summary()\n",
    "\n",
    "\n",
    "    def train_model(self, model_name, epochs=1000):\n",
    "        model_name = model_name + '--{epoch:02d}--{val_accuracy:.2f}.h5'\n",
    "\n",
    "        def save_best_model(save_as):\n",
    "            checkpoint = ModelCheckpoint(filepath=save_as,\n",
    "                                         monitor='val_accuracy',\n",
    "                                         verbose=0,\n",
    "                                         save_best_only=True,\n",
    "                                         mode='max')\n",
    "            return checkpoint\n",
    "\n",
    "        history = self.model.fit(self.X_train, self.y_train,\n",
    "                                 epochs=epochs,\n",
    "                                 shuffle=False,\n",
    "                                 batch_size=128,\n",
    "                                 validation_data=(self.X_test, self.y_test),\n",
    "                                 callbacks=[save_best_model(model_name)],\n",
    "                                 verbose=0)\n",
    "\n",
    "        self.history = history\n",
    "\n",
    "\n",
    "\n",
    "    def plots(self):\n",
    "        metrics = Metrics(self.model, self.history, self.X_test, self.y_test)\n",
    "        metrics.plot_loss_accuracy()\n",
    "      \n",
    "        print(metrics.calculate_precision_recall_f1())\n",
    "        metrics.plot_confusion_matrix()\n",
    "        metrics.plot_roc_curve()\n",
    "\n",
    "\n",
    "    def get_history(self):\n",
    "        return self.history\n",
    "\n",
    "    \n",
    "    def get_model(self,model_name):\n",
    "        return load_model(model_name)\n",
    "    \n",
    "    \n",
    "    def build_layers(self,model_name):\n",
    "        self.trained_model = load_model(model_name)\n",
    "\n",
    "        kernel_initializer1 = tf.keras.initializers.constant(self.trained_model.trainable_weights[0])\n",
    "        bias_initializer1 = tf.keras.initializers.constant(self.trained_model.trainable_weights[1])\n",
    "\n",
    "        kernel_initializer2 = tf.keras.initializers.constant(self.trained_model.trainable_weights[2])\n",
    "        bias_initializer2 = tf.keras.initializers.constant(self.trained_model.trainable_weights[3])\n",
    "\n",
    "        \n",
    "        Inputs = Input(shape=(int(self.data[0].shape[0],),))\n",
    "        x = Dense(units=self.hidden_nodes, \n",
    "                  activation=\"linear\", \n",
    "                  kernel_initializer = kernel_initializer1,\n",
    "                  bias_initializer= bias_initializer1)(Inputs)\n",
    "        \n",
    "        x = LeakyReLU(alpha=0.4)(x)\n",
    "        \n",
    "        x = Dense(units=2, activation=\"softmax\", \n",
    "                        kernel_initializer = kernel_initializer2, \n",
    "                        bias_initializer = bias_initializer2)(x)\n",
    "        \n",
    "        return Inputs,x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with MODALITY 1 (EEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_1 = Modality(data=data['mod1'],labels=labels_v,regularization=0.6)\n",
    "modality_1.build_model(neurons=33)\n",
    "modality_1.train_model(model_name=\"mod1\",epochs=1000)\n",
    "modality_1.plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with MODALITY 2 (EOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_2 = Modality(data=data['mod2'],labels=labels_v)\n",
    "modality_2.build_model(neurons=12)\n",
    "modality_2.train_model(model_name=\"mod2\",epochs=2000)\n",
    "modality_2.plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with MODALITY 3 (EMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_3 = Modality(data=data['mod3'],labels=labels_v)\n",
    "modality_3.build_model(neurons=11)\n",
    "modality_3.train_model(model_name=\"mod3\",epochs=1500)\n",
    "modality_3.plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with MODALITY 4 (GSR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_4 = Modality(data=data['mod4'],labels=labels_v)\n",
    "modality_4.build_model(neurons=9)\n",
    "modality_4.train_model(model_name=\"mod4\",epochs=2000)\n",
    "modality_4.plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with MODALITY 5 (RESP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_5 = Modality(data=data['mod3'],labels=labels_v)\n",
    "modality_5.build_model(neurons=13)\n",
    "modality_5.train_model(model_name=\"mod5\",epochs=1500)\n",
    "modality_5.plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with MODALITY 6 (PLET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_6 = Modality(data=data['mod6'],labels=labels_v)\n",
    "modality_6.build_model(neurons=9)\n",
    "modality_6.train_model(model_name=\"mod6\",epochs=1500)\n",
    "modality_6.plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with MODALITY 7 (TEMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_7 = Modality(data=data['mod7'],labels=labels_v)\n",
    "modality_7.build_model(neurons=8)\n",
    "modality_7.train_model(model_name=\"mod7\",epochs=3000)\n",
    "modality_7.plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Average Fusion Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_models = 0\n",
    "min_modalities = 1\n",
    "max_modalities = 7\n",
    "\n",
    "# Calculate the total number of models for combinations from 1 to 7 modalities\n",
    "for k in range(min_modalities, max_modalities + 1):\n",
    "    combinations = math.comb(max_modalities, k)\n",
    "    total_models += combinations\n",
    "\n",
    "print(\"Total number of models for different combinations of 1 to 7 modalities:\", total_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedAverage(Layer):\n",
    "\n",
    "    def __init__(self, n_output):\n",
    "        super(WeightedAverage, self).__init__()\n",
    "        self.W = tf.Variable(initial_value=tf.random.uniform(shape=[1,1,n_output], minval=0, maxval=1,seed=42),trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [tf.expand_dims(i, -1) for i in inputs]\n",
    "        inputs = Concatenate(axis=-1)(inputs)\n",
    "        weights = tf.nn.softmax(self.W, axis=-1)\n",
    "        return tf.reduce_sum(weights*inputs, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL MODALITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_files = glob.glob(\"*.h5\")\n",
    "\n",
    "modalities = {}\n",
    "\n",
    "pattern = r'(mod\\d+)--\\d+--(\\d+\\.\\d+)\\.h5'\n",
    "\n",
    "for file in saved_model_files:\n",
    "    match = re.match(pattern, file)\n",
    "    if match:\n",
    "        modality, accuracy = match.groups()\n",
    "        accuracy = float(accuracy)\n",
    "        \n",
    "        if modality not in modalities or accuracy > modalities[modality]['accuracy']:\n",
    "            modalities[modality] = {'accuracy': accuracy, 'filename': file}\n",
    "\n",
    "for modality, data in modalities.items():\n",
    "    print(f\"Max accuracy for {modality}: {data['accuracy']} (Filename: {data['filename']})\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities[\"mod1\"][\"filename\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the saved best performing models in each modality\n",
    "\n",
    "# MOD1_INPUT, mod1_mlp = modality_1.build_layers(model_name=\"mod1--726--0.43.h5\")\n",
    "# MOD2_INPUT, mod2_mlp = modality_2.build_layers(model_name=\"mod2--989--0.62.h5\")\n",
    "# MOD3_INPUT, mod3_mlp = modality_3.build_layers(model_name=\"mod3--44--0.70.h5\")\n",
    "# MOD4_INPUT, mod4_mlp = modality_4.build_layers(model_name=\"mod4--1428--0.60.h5\")\n",
    "# MOD5_INPUT, mod5_mlp = modality_5.build_layers(model_name=\"mod5--238--0.55.h5\")\n",
    "# MOD6_INPUT, mod6_mlp = modality_6.build_layers(model_name=\"mod6--687--0.60.h5\")\n",
    "# MOD7_INPUT, mod7_mlp = modality_7.build_layers(model_name=\"mod7--539--0.57.h5\")\n",
    "\n",
    "\n",
    "MOD1_INPUT, mod1_mlp = modality_1.build_layers(model_name= modalities[\"mod1\"][\"filename\"])\n",
    "MOD2_INPUT, mod2_mlp = modality_2.build_layers(model_name= modalities[\"mod2\"][\"filename\"])\n",
    "MOD3_INPUT, mod3_mlp = modality_3.build_layers(model_name= modalities[\"mod3\"][\"filename\"])\n",
    "MOD4_INPUT, mod4_mlp = modality_4.build_layers(model_name= modalities[\"mod4\"][\"filename\"])\n",
    "MOD5_INPUT, mod5_mlp = modality_5.build_layers(model_name= modalities[\"mod5\"][\"filename\"])\n",
    "MOD6_INPUT, mod6_mlp = modality_6.build_layers(model_name= modalities[\"mod6\"][\"filename\"])\n",
    "MOD7_INPUT, mod7_mlp = modality_7.build_layers(model_name= modalities[\"mod7\"][\"filename\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fusion models and input list\n",
    "all_models = [mod1_mlp, mod2_mlp, mod3_mlp, mod4_mlp, mod5_mlp, mod6_mlp, mod7_mlp]\n",
    "\n",
    "all_inputs = [MOD1_INPUT,\n",
    "              MOD2_INPUT,\n",
    "              MOD3_INPUT,\n",
    "              MOD4_INPUT,\n",
    "              MOD5_INPUT,\n",
    "              MOD6_INPUT,\n",
    "              MOD7_INPUT]\n",
    "\n",
    "all_train = [modality_1.X_train,\n",
    "             modality_2.X_train,\n",
    "             modality_3.X_train,\n",
    "             modality_4.X_train,\n",
    "             modality_5.X_train,\n",
    "             modality_6.X_train,\n",
    "             modality_7.X_train]\n",
    "\n",
    "all_train_labels = modality_1.y_train\n",
    "            \n",
    "all_test = [modality_1.X_test,\n",
    "            modality_2.X_test,\n",
    "            modality_3.X_test,\n",
    "            modality_4.X_test,\n",
    "            modality_5.X_test,\n",
    "            modality_6.X_test,\n",
    "            modality_7.X_test]\n",
    "\n",
    "all_test_labels = modality_1.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fused_model(selected_models,selected_inputs):\n",
    "    model = selected_models\n",
    "    wt_avg_layer = WeightedAverage(n_output=len(model))(model)\n",
    "    output =  Dense(2, activation=\"softmax\", kernel_initializer=he_normal(seed=42))(wt_avg_layer)\n",
    "\n",
    "    model = Model(inputs=selected_inputs,\n",
    "                        outputs=output)\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=\"accuracy\")\n",
    "    # model.summary()\n",
    "    return model\n",
    "\n",
    "def train_fused_model(model,X_train,y_train,X_test,y_test):\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=1000,\n",
    "                        batch_size=128,\n",
    "                        verbose=0,\n",
    "                        shuffle=False, \n",
    "                        validation_data=(X_test,y_test))\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_train_labels = all_train_labels\n",
    "selected_test_labels = all_test_labels\n",
    "    \n",
    "def train_combinations(num_modalites):\n",
    "    all_accuracies = []\n",
    "    all_mod_combinations = []\n",
    "    combinations = list(itertools.combinations(range(1, 8), num_modalites))\n",
    "\n",
    "    progress_bar = tqdm.tqdm(desc=\"Training different combinations\", total=len(combinations), dynamic_ncols=True)\n",
    "    for combination in combinations:\n",
    "        mod_combinations = [MODALITIES[i - 1] for i in combination]\n",
    "        # print(mod_combinations)\n",
    "        # progress_bar.set_description(f\"Training model with modalities: {combination} or {mod_combinations}\", refresh=True)\n",
    "        print(f\"Training model with modalities: {combination} or {mod_combinations}\")\n",
    "        selected_models = [all_models[i - 1] for i in combination]\n",
    "        selected_inputs = [all_inputs[i - 1] for i in combination]\n",
    "        selected_train = [all_train[i - 1] for i in combination]\n",
    "        selected_test = [all_test[i - 1] for i in combination]\n",
    "\n",
    "        model = build_fused_model(selected_models, selected_inputs)\n",
    "        _, history = train_fused_model(model,\n",
    "                                       selected_train,\n",
    "                                       selected_train_labels,\n",
    "                                       selected_test,\n",
    "                                       selected_test_labels)\n",
    "\n",
    "        max_accuracy = np.max(history.history[\"val_accuracy\"])\n",
    "        print(\"Maximum Validation Accuracy for this combination: {:.2f}\".format(max_accuracy))\n",
    "\n",
    "        all_accuracies.append(max_accuracy)\n",
    "        all_mod_combinations.append(mod_combinations)\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()\n",
    "    return all_accuracies, all_mod_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fused_model(best_combination):\n",
    "    selected_models = [all_models[i-1] for i in best_combination]\n",
    "    selected_inputs = [all_inputs[i-1] for i in best_combination]\n",
    "    selected_train = [all_train[i-1] for i in best_combination]\n",
    "    selected_test = [all_test[i-1] for i in best_combination]\n",
    "    best_model = build_fused_model(selected_models, selected_inputs)\n",
    "    best_model, history = train_fused_model(best_model,\n",
    "                                        selected_train,\n",
    "                                        selected_train_labels,\n",
    "                                        selected_test,\n",
    "                                        selected_test_labels)\n",
    "\n",
    "    best_model_metrics = Metrics(best_model,history,selected_test, all_test_labels)\n",
    "    best_model_metrics.plot_loss_accuracy()\n",
    "    print(best_model_metrics.calculate_precision_recall_f1())\n",
    "    best_model_metrics.plot_confusion_matrix()\n",
    "    best_model_metrics.plot_roc_curve()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the weighted average fusion layer\n",
    "mod1_7 = all_models\n",
    "wt_avg_layer = WeightedAverage(n_output=len(mod1_7))(mod1_7)\n",
    "output =  Dense(2, activation=\"softmax\")(wt_avg_layer)\n",
    "\n",
    "mod1_7_model = Model(inputs=all_inputs,\n",
    "                     outputs=output)\n",
    "\n",
    "mod1_7_model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=\"accuracy\")\n",
    "mod1_7_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1_7_model_history = mod1_7_model.fit(all_train,\n",
    "                                        all_train_labels ,\n",
    "                                        epochs=1000,\n",
    "                                        batch_size=128,\n",
    "                                        verbose=2,\n",
    "                                        shuffle=False, \n",
    "                                        validation_data=(all_test,\n",
    "                                                         all_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the learned value of weights\n",
    "tf.nn.softmax(mod1_7_model.get_weights()[-3]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1_7_metrics = Metrics(mod1_7_model,mod1_7_model_history,all_test, all_test_labels)\n",
    "mod1_7_metrics.plot_loss_accuracy()\n",
    "print(mod1_7_metrics.calculate_precision_recall_f1())\n",
    "mod1_7_metrics.plot_confusion_matrix()\n",
    "mod1_7_metrics.plot_roc_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mod_accuracies, all_mod_combinations = train_combinations(num_modalites=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc_index = np.argmax(all_mod_accuracies) \n",
    "print(f\"Highest accuracy from all possible combinations for seven modalities is {all_mod_accuracies[max_acc_index]:.2f} for {all_mod_combinations[max_acc_index]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIX MODALITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "six_mod_accuracies, six_mod_combinations = train_combinations(num_modalites=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc_index = np.argmax(six_mod_accuracies) \n",
    "print(f\"Highest accuracy from all possible combinations for six modalities is {six_mod_accuracies[max_acc_index]:.2f} for {six_mod_combinations[max_acc_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_six = [MODALITY_INDICES[modality] for modality in six_mod_combinations[max_acc_index]]\n",
    "print(best_six)\n",
    "evaluate_fused_model(best_six)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIVE MODALITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_mod_accuracies, five_mod_combinations = train_combinations(num_modalites=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc_index = np.argmax(five_mod_accuracies) \n",
    "print(f\"Highest accuracy from all possible combinations for five modalities is {five_mod_accuracies[max_acc_index]:.2f} for {five_mod_combinations[max_acc_index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_five = ['EEG', 'EOG', 'EMG', 'GSR', 'RESP']\n",
    "\n",
    "best_five =  [MODALITY_INDICES[modality] for modality in five_mod_combinations[max_acc_index]]\n",
    "print(best_five)\n",
    "evaluate_fused_model(best_five)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOUR MODALITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_mod_accuracies, four_mod_combinations = train_combinations(num_modalites=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc_index = np.argmax(four_mod_accuracies) \n",
    "print(f\"Highest accuracy from all possible combinations for four modalities is {four_mod_accuracies[max_acc_index]:.2f} for {four_mod_combinations[max_acc_index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_four =  [MODALITY_INDICES[modality] for modality in four_mod_combinations[max_acc_index]]\n",
    "print(best_four)\n",
    "evaluate_fused_model(best_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THREE MODALITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_mod_accuracies, three_mod_combinations = train_combinations(num_modalites=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc_index = np.argmax(three_mod_accuracies) \n",
    "print(f\"Highest accuracy from all possible combinations for three modalities is {three_mod_accuracies[max_acc_index]:.2f} for {three_mod_combinations[max_acc_index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_three = ['EOG', 'GSR', 'temp']\n",
    "\n",
    "best_three = [MODALITY_INDICES[modality] for modality in three_mod_combinations[max_acc_index]]\n",
    "print(best_three)\n",
    "evaluate_fused_model(best_three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TWO MODALITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_mod_accuracies, two_mod_combinations = train_combinations(num_modalites=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc_index = np.argmax(two_mod_accuracies) \n",
    "print(f\"Highest accuracy from all possible combinations for two modalities is {two_mod_accuracies[max_acc_index]:.2f} for {two_mod_combinations[max_acc_index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_two =  [MODALITY_INDICES[modality] for modality in two_mod_combinations[max_acc_index]]\n",
    "print(best_two)\n",
    "evaluate_fused_model(best_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONE MODALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_mod_accuracies, one_mod_combinations = train_combinations(num_modalites=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc_index = np.argmax(one_mod_accuracies) \n",
    "print(f\"Highest accuracy from all possible combinations for one modalities is {one_mod_accuracies[max_acc_index]:.2f} for {one_mod_combinations[max_acc_index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mod_sel_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
